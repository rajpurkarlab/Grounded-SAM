{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training for Grounded SAM.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import SamProcessor\n",
    "\n",
    "from linear_probe import LinearProbe\n",
    "from utils import get_bounding_box\n",
    "\n",
    "from model import myGroundingDino, myBiomedCLIP, mySAM\n",
    "import dataset_mimic\n",
    "import dataset_pascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adaptation(hyperparams):\n",
    "    \"\"\"Training script for adaptation loss only (to be combined with segmentation objective).\n",
    "    \"\"\"\n",
    "    # Load hyperparameters\n",
    "    lr = hyperparams['lr']\n",
    "    batch_size = hyperparams['batch_size']\n",
    "    num_epochs = hyperparams['num_epochs']\n",
    "    num_workers = hyperparams['num_workers']\n",
    "    device = hyperparams['device']\n",
    "    save_folder = hyperparams['save_folder']\n",
    "\n",
    "\n",
    "    # Load data\n",
    "    mimic_dataloader = dataset_mimic.load_data(batch_size=batch_size, tensor=True)\n",
    "    print(mimic_dataloader)\n",
    "\n",
    "    # Load model\n",
    "    my_groundingdino = myGroundingDino(device=device)\n",
    "    my_sam = mySAM(device=device)\n",
    "    my_biomedclip = myBiomedCLIP(device=device)\n",
    "\n",
    "    # Load optimizer\n",
    "    groundingdino_params = list(my_groundingdino.model.backbone.parameters()) + list(my_groundingdino.img_linear.parameters()) + list(my_groundingdino.text_linear.parameters())\n",
    "    sam_params = list(my_sam.model.parameters()) + list(my_sam.img_linear.parameters())\n",
    "    optimizer = torch.optim.Adam(groundingdino_params + sam_params, lr=lr)\n",
    "\n",
    "    # Set up training mode\n",
    "    my_groundingdino.model.backbone.train()\n",
    "    my_groundingdino.img_linear.train()\n",
    "    my_groundingdino.text_linear.train()\n",
    "    my_sam.model.train()\n",
    "    my_sam.img_linear.train()\n",
    "    my_biomedclip.model.eval()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for data in tqdm(mimic_dataloader, desc=f'Training @ epoch {epoch+1} of {num_epochs}'):\n",
    "            # Load data\n",
    "            images = data[\"image\"]\n",
    "            image_paths = data[\"image_path\"]\n",
    "            report = data[\"report\"]\n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            loss = pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Save model\n",
    "    my_groundingdino.save(ckpt_folder=save_folder)\n",
    "    my_sam.save(ckpt_folder=save_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grounded_sam",
   "language": "python",
   "name": "grounded_sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
